{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZKpRE0JbLbGp"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Oex88qd38Thn"},"source":["Using pandas to import features and label files.\n","\n","Among 569 rows of data(instances), I split into estimated 80% data for training and 20% data for testing. The training data was used for training the machine with model. The testing data feeds into the trained model to predict an outcome.\n","\n","* These files are pre-processed.\n","* These files are uploaded already by me to github.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m_NRnXsJzphf","colab":{}},"source":["import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# import feature train data\n","feature_train = pd.read_csv(\"https://raw.githubusercontent.com/yyoo79/swe645hw5/master/feature_train.csv\", header=None)\n","# import label train data\n","label_train = pd.read_csv(\"https://raw.githubusercontent.com/yyoo79/swe645hw5/master/label_train.csv\", header=None)\n","# import feature testing data\n","feature_test = pd.read_csv(\"https://raw.githubusercontent.com/yyoo79/swe645hw5/master/feature_test.csv\", header=None)\n","# import label testing data\n","label_test = pd.read_csv(\"https://raw.githubusercontent.com/yyoo79/swe645hw5/master/label_test.csv\", header=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iLe9WR2SvBnz","colab":{}},"source":["#View and verify feature_train data is correctly imported\n","feature_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ooiZ7Rw61GiV","colab":{}},"source":["#View and verify label_train data is correctly imported\n","label_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ew8riFDp24dW","colab":{}},"source":["#View and verify feature testing data is correctly imported\n","feature_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BzmHyo5b25-x","colab":{}},"source":["#View and verify label testing data is correctly imported\n","label_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bL4z0BArzqff"},"source":["Create Sequential model and add 3 2D layers(Dense) plus sigmoid.\n","Sequential model is a linear stack of layers.\n","`.add()` method is used to add layers.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LoWtmalR80De","outputId":"de82e9d1-2022-4713-ccdd-008dfb28d969","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1569698386644,"user_tz":240,"elapsed":8025,"user":{"displayName":"YangKyu Yoo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCnVwbqV8ikIxH-0S_uFuf9vHnBtv1wzoXLrv5KEw=s64","userId":"13506594103597094752"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# creating Sequential model\n","model = Sequential()\n","\n","model.add(Dense(units = 16, activation = 'relu', input_dim = 30))\n","model.add(Dense(units = 8, activation = 'relu'))\n","model.add(Dense(units = 6, activation = 'relu'))\n","model.add(Dense(units = 1, activation = 'sigmoid'))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cJ_MStxe9CbN"},"source":["Now compile with optimizer - rmsptrop and loss binary crossentropy.\n","*   RMSProp - usually a good choice for recurrent neural networks.\n","*   binary_crossentropy - this loss functions works well with sigmoid activation for making a binary choice for N questions.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c_RYBJvIbUuk","outputId":"c0727250-ff1e-44c5-e13e-24ed0a03a0da","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1569698386854,"user_tz":240,"elapsed":8215,"user":{"displayName":"YangKyu Yoo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCnVwbqV8ikIxH-0S_uFuf9vHnBtv1wzoXLrv5KEw=s64","userId":"13506594103597094752"}}},"source":["# For a binary classification problem\n","model.compile(optimizer='rmsprop',\n","              loss = 'binary_crossentropy')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ai-cu6SyPPs1","colab":{}},"source":["# view model summary\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Mn9WPqaP9RmN"},"source":["Now, training. I am using model.fit() function to train data.\n","Parameters:\n","* feature_train - prepared data for x\n","* label_train - prepared data for y\n","* batch_size = 1 - I set just 1 number of samples per gradient\n","* epochs = 60 - I set 60 loops to examine the progress over iteration\n","\n","Note:\n","* batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n","* epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Note that in conjunction with initial_epoch,  epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1QlYnFgH9N49","colab":{}},"source":["model.fit(feature_train, label_train, batch_size = 1, epochs = 60)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eQPLEcjOaYJn"},"source":["Note that loss is ~ between 0.02 and 0.04 which is approximately 2-4% range."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yrnGgtfn9gsE"},"source":["Now, save prediction output label values to variables - label_prediction. The `.prediction()` function to predict new values and passing feature_test data set to the function call.\n","\n","These predictions outcome will return decimal value between 0 and 1. In my case, I will set 1(true) if the values are greater than .5, else 0(false)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xEaG0Tkx9fUU","colab":{}},"source":["label_prediction = model.predict(feature_test)\n","\n","for i in range(len(label_prediction)):\n","  if label_prediction[i] >= 0.5:\n","    label_prediction[i] = 1\n","  else:\n","    label_prediction[i] = 0\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eujlw_WA5Wm6","colab":{}},"source":["label_prediction"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oQK3Qo9h97OW"},"source":["Now, I have `label_prediction` variables with prediction values.\n","\n","I can iterate through the set of predictions for test set in variable name - label_pred and then, compare with actual values of test set - variable name - label_test. We will count 'Correct' and 'Wrong' count depends on result value.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"he_2VHJ_9yC1","outputId":"a3febded-d91e-48fc-f647-478ae7e7e404","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1569698418535,"user_tz":240,"elapsed":39823,"user":{"displayName":"YangKyu Yoo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCnVwbqV8ikIxH-0S_uFuf9vHnBtv1wzoXLrv5KEw=s64","userId":"13506594103597094752"}}},"source":["total_count = 0\n","correct_count = 0\n","wrong_count = 0\n","\n","for i in range(len(label_prediction)):\n","  total_count = total_count + 1\n","  if(label_test.at[i,0] == label_prediction[i]):\n","    correct_count = correct_count + 1\n","  else:\n","    wrong_count = wrong_count + 1\n","\n","print(\"Total count of data: \" + str(total_count))\n","print(\"Correct count of test vs. pred: \" + str(correct_count))\n","print(\"Wrong count of test vs. pred: \" + str(wrong_count))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Total count of data: 114\n","Correct count of test vs. pred: 112\n","Wrong count of test vs. pred: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xg1Pvt35glxd"},"source":["The result is about accuracy of 96-98%."]}]}